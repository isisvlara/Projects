# -*- coding: utf-8 -*-
"""12.2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RvkYeC_zm_IugpLivNw8Kv5WWAIpHmcB
"""

pip install tinydb

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
from tinydb import TinyDB, Query
from pyspark.sql import SparkSession
from pyspark.ml.feature import VectorAssembler
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
import tensorflow as tf
from tensorflow import keras
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from transformers import BertTokenizer, TFBertForSequenceClassification
import nltk
nltk.download('punkt_tab')
nltk.download('stopwords')

"""1.) Data Ingestion and Storage

"""

db = TinyDB('customer_reviews.json')

# Simulating data generation
np.random.seed(42)
n_samples = 5000

user_ids = np.arange(1, n_samples + 1)
product_ids = np.random.randint(1, 1001, n_samples)
ratings = np.random.randint(1, 6, n_samples)
review_lengths = np.random.randint(10, 200, n_samples)
purchase_amounts = np.random.uniform(10, 1000, n_samples)
customer_ages = np.random.randint(18, 80, n_samples)

# Generate random review text (simplified)
review_texts = [f"This product is {'great' if rating > 3 else 'poor'}. {'Recommended' if rating > 3 else 'Not recommended'}." for rating in ratings]

# Store data in TinyDB
for i in range(n_samples):
    db.insert({
        'user_id': int(user_ids[i]),
        'product_id': int(product_ids[i]),
        'rating': int(ratings[i]),
        'review_length': int(review_lengths[i]),
        'purchase_amount': float(purchase_amounts[i]),
        'customer_age': int(customer_ages[i]),
        'review_text': review_texts[i]
    })

"""2.) Data Processing and Analysis with Pandas"""

# Data cleaning and feature engineering
df = pd.DataFrame(db.all())

df['sentiment'] = df['rating'].apply(lambda x: 'positive' if x > 3 else 'negative')
df['review_word_count'] = df['review_text'].apply(lambda x: len(word_tokenize(x)))

"""3.) Data Visualization"""

# Static visualization with Matplotlib and Seaborn
plt.figure(figsize=(10, 6))
sns.boxplot(x='sentiment', y='purchase_amount', data=df)
plt.title('Purchase Amount Distribution by Sentiment')
plt.savefig('sentiment_purchase_distribution.png')
plt.close()

# Interactive visualization with Plotly
fig = px.scatter(df, x='customer_age', y='purchase_amount', color='sentiment',
                 hover_data=['rating', 'review_word_count'])
fig.write_html('age_purchase_scatter.html')

"""4.) Statistical Analysis with Statsmodel"""

import statsmodels.api as sm

X = df[['customer_age', 'review_word_count']]
y = df['purchase_amount']
X = sm.add_constant(X)
model = sm.OLS(y, X).fit()
print(model.summary())

"""5.) Machine Learning with Pyspark and Mlib"""

spark = SparkSession.builder.appName("CustomerReviewAnalysis").getOrCreate()

# Convert Pandas DataFrame to Spark DataFrame
spark_df = spark.createDataFrame(df)

# Prepare features for ML model
feature_cols = ['customer_age', 'review_word_count', 'purchase_amount']
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
data = assembler.transform(spark_df)

# Split data into training and testing sets
train_data, test_data = data.randomSplit([0.8, 0.2], seed=42)

# Train Random Forest Classifier
rf = RandomForestClassifier(labelCol="rating", featuresCol="features", numTrees=10)
model = rf.fit(train_data)

# Make predictions and evaluate the model
predictions = model.transform(test_data)
evaluator = MulticlassClassificationEvaluator(labelCol="rating", predictionCol="prediction", metricName="accuracy")
accuracy = evaluator.evaluate(predictions)
print(f"Random Forest Accuracy: {accuracy}")

"""6.) Deep Learning with TensorFlow and Keras"""

# Prepare data for deep learning
X_dl = df[['customer_age', 'review_word_count', 'purchase_amount']].values
y_dl = df['rating'].values - 1  # Adjust ratings to start from 0

# Build and train a simple neural network
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(3,)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(5, activation='softmax')
])

model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
model.fit(X_dl, y_dl, epochs=10, validation_split=0.2)

"""7.) Natural Language Processing with NLTK and Transformers"""

# Tokenize and remove stopwords
stop_words = set(stopwords.words('english'))
df['processed_text'] = df['review_text'].apply(lambda x: ' '.join([word.lower() for word in word_tokenize(x) if word.lower() not in stop_words]))

# Use BERT for sentiment analysis
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')

# Prepare data for BERT
inputs = tokenizer(df['processed_text'].tolist(), padding=True, truncation=True, return_tensors="tf")
outputs = model(inputs)
predictions = tf.nn.softmax(outputs.logits, axis=-1)
df['bert_sentiment'] = tf.argmax(predictions, axis=-1).numpy()

model.save('deep_learning_model', save_format='tf')

"""8.) Model Deployement with Streamlit"""

pip install streamlit

import streamlit as st
import pandas as pd
import numpy as np
import tensorflow as tf
from transformers import BertTokenizer, TFBertForSequenceClassification

# Load your trained models
@st.cache(allow_output_mutation=True)
def load_models():
    # Load the deep learning model
    dl_model = tf.keras.models.load_model('deep_learning_model')

    # Load the BERT model and tokenizer
    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
    bert_model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')

    return dl_model, tokenizer, bert_model

dl_model, tokenizer, bert_model = load_models()

# Streamlit app
st.title('Customer Review Analysis')

# Input fields
st.header('Enter Customer Information')
customer_age = st.slider('Customer Age', 18, 80, 30)
review_word_count = st.number_input('Review Word Count', min_value=1, max_value=500, value=50)
purchase_amount = st.number_input('Purchase Amount', min_value=10.0, max_value=1000.0, value=100.0)
review_text = st.text_area('Review Text', 'Enter the customer review here...')

# Predict button
if st.button('Analyze Review'):
    # Deep Learning model prediction
    dl_input = np.array([[customer_age, review_word_count, purchase_amount]])
    dl_prediction = dl_model.predict(dl_input)
    predicted_rating = np.argmax(dl_prediction) + 1  # Add 1 to shift back to 1-5 scale

    # BERT sentiment analysis
    inputs = tokenizer(review_text, padding=True, truncation=True, return_tensors="tf")
    outputs = bert_model(inputs)
    predictions = tf.nn.softmax(outputs.logits, axis=-1)
    bert_sentiment = tf.argmax(predictions, axis=-1).numpy()[0]
    sentiment = 'Positive' if bert_sentiment == 1 else 'Negative'

    # Display results
    st.header('Analysis Results')
    st.write(f'Predicted Rating: {predicted_rating}/5')
    st.write(f'Sentiment Analysis: {sentiment}')